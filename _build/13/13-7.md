---
interact_link: content/C:\Users\lbj\Desktop\book\content\13/13-7.ipynb
kernel_name: python3
has_widgets: false
title: '13-7 使用 PCA 的建议'
prev_page:
  url: /13/13-6
  title: '13-6 压缩表示重建'
next_page:
  url: /14/14-1
  title: '14-1 问题驱动'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 使用 PCA 的建议

假使我们正在针对一张 100×100 像素的图片进行某个计算机视觉的机器学习，即总共有 10000 个特征。 
1. 第一步是运用主要成分分析将数据压缩至 1000 个特征 
2. 然后对训练集运行学习算法 
3. 在预测时，采用之前学习而来的$U_{reduce}$将输入的特征 x 转换成特征向量 z，然后再进行预测      
注：如果我们有交叉验证集合测试集，也采用对训练集学习而来的$U_{reduce}$。 

一个常见错误使用主要成分分析的情况是，将其用于减少过拟合（减少了特征的数量）。这样做非常不好，不如尝试正则化处理。原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息，因此可能会丢失非常重要的特征。然而当我们进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。 

另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。

