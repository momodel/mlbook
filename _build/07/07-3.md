---
interact_link: content/C:\Users\lbj\Desktop\book\content\07/07-3.ipynb
kernel_name: python3
has_widgets: false
title: '07-3 模型表示 I'
prev_page:
  url: /07/07-2
  title: '07-2 神经元与大脑'
next_page:
  url: /07/07-4
  title: '07-4 模型表示 II'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 模型表示 I


+ 大脑的神经网络
+ 神经网络建模

**大脑神经网络运行原理**


每一个神经元都可以被认为是一个处理单元/神经核（processing unit/ Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链
接并通过电脉冲来交流的一个网络。

![](https://i.loli.net/2018/12/01/5c01f1c180e39.png)
 
神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元。 

所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。 

**神经网络模型** 

神经网络模型是许多神经元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输入，并且根据本身的模型提供一个输出。下图为一个 3 层的神经网络，第一层称为输入层（Input Layer），最后一
层称为输出层（Output Layer），中间一层称为隐藏层（Hidden Layers）。在神经网络中，参数又可被称为权重（weight）。我们为每一层都增加一个偏差单位（bias unit）

![](https://i.loli.net/2018/12/01/5c01f2d2b8ac5.png)

其中，$x_1$,$x_2$,$x_3$是输入单元（input units），我们将原始数据输入给它们。$a^{(2)}\_1$，$a^{(2)}\_2$，$a^{(2)}\_3$ 
是中间单元，它们负责将数据进行处理，然后呈递到下一层。 最后是输出单元，它负责计算$h\_\theta(x)$。

下面引入一些标记法来帮助描述模型： 
$a^{(j)}_i$代表第 j 层的第 i 个激活单元。$\theta^{(j)}$
代表从第 j 层映射到第 j+1 层时的权重的矩阵，其尺寸为：以第 j+1 层的激活单元数量为行数，以第 j 层的激活单元数加一为列数的矩阵。例如$\theta^{(1)}$代表从第一层映射到第二层的权重的矩阵,它的尺寸为 3*4。 

对于上图所示的模型，激活单元和输出分别表达为： 

![](https://imgbed.momodel.cn/20200519111250.png)

上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。 
我们可以知道：每一个 a 都是由上一层所有的 x 和每一个 x 所对应的 $\theta$决定的。 
（我们把这样从左到右的算法称为前向传播算法( FORWARD PROPAGATION )）  
