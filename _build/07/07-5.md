---
interact_link: content/C:\Users\lbj\Desktop\book\content\07/07-5.ipynb
kernel_name: python3
has_widgets: false
title: '07-5 模型表示实例 I'
prev_page:
  url: /07/07-4
  title: '07-4 模型表示 II'
next_page:
  url: /07/07-6
  title: '07-6 模型表示实例 II'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

### 模型表示实例 I


+ 神经网络的样例与直观理解
+ 单层神经元表示逻辑运算: 逻辑与（AND）、逻辑或（OR）

**神经网络的直观理解** 

从本质上讲，神经网络能够通过学习得出其自身的一系列特征。

在普通的逻辑回归中，我们被限制为使用数据中的原始特征$x_0, x_1, x_2, x_3$我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。

在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。 

神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与（AND）、逻辑或（OR）。 


**逻辑与（AND)</span>**     

我们可以用这样的一个神经网络表示 AND 函数： 假设输入$x_1,x_2 \in {{0,1}}$

![](https://i.loli.net/2018/12/01/5c02010c8316e.png)


其中 $\theta_0 = -30$, $\theta_1 = 20$, $\theta_2 = 20$
输出函数 $h_\theta(x)$即为：$h_\theta(x)=g(-30 + 20x_1 + 20x_2)$

g(x)的图像是：

![](https://i.loli.net/2018/12/01/5c0201e951df7.png)


 
 那么，$x_1,x_2$一共四种可能取值，得到的结果分别如下：
 
![](https://i.loli.net/2018/12/01/5c02022294aa9.png)

所以我们的： $h_\theta(x) \approx x_1 AND x_2$。

逻辑或（OR） 与 AND 整体一样，区别只在于权值的取值不同。

**牛刀小试**

我们来实现一个单层网络(感知机).

<div markdown="1" class="cell code_cell">
<div class="input_area" markdown="1">
```python
# todo 实现与网络

import numpy as np

def sigmoid(x):
    return 1/(1+np.exp(-x))

class Net():
    def __init__(self,theta):
        self.theta=theta
    def run(self,X):   
        output = sigmoid(np.matmul(self.theta,X))
        return output

net = Net(np.array([[-30,20,20]]))
    

```
</div>

</div>
